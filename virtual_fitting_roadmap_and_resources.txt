# 온라인 의류 쇼핑몰 2D→3D 가상 피팅 시스템 개발 로드맵 및 참고 오픈소스/자료 (2024년 6월, 정상 링크 재점검)

## 1. 목표
- 2D 의류 이미지를 클릭하면, AI가 자동으로 3D 의상 모델로 변환
- 사용자 아바타(3D)에 해당 의상을 자동 피팅하여 실시간 시뮬레이션
- 웹/모바일에서 누구나 쉽게 3D 가상 피팅 체험

## 2. 상세 워크플로우
1. 쇼핑몰에서 2D 옷 사진 클릭
2. AI가 2D 이미지를 3D 의상 모델로 자동 변환
3. 사용자 신체 치수 기반 3D 아바타 생성 또는 선택
4. 3D 의상 모델을 아바타에 자동 피팅(물리 시뮬레이션 포함)
5. 웹에서 실시간 3D 시뮬레이션/회전/확대/포즈 변경
6. 다양한 각도/포즈/조명에서 착용 모습 확인

## 3. 필요한 핵심 AI/툴/기술 및 오픈소스 다운로드 링크 (2024년 6월 기준, 정상 링크)

### 3.1 2D→3D 의상/인체 복원 AI
- **PIFuHD** (2D 전신 이미지 → 3D 인체 메쉬)
  - [GitHub](https://github.com/facebookresearch/pifuhd)
  - [논문](https://arxiv.org/abs/2004.00452)
- **DreamHuman** (텍스트/이미지 기반 3D 인체 생성)
  - [GitHub](https://github.com/ashawkey/dreamhuman)
  - [공식 페이지](https://dreamhuman.github.io/)
- **Meshy** (텍스트/이미지 → 3D 모델 생성, 상용 서비스)
  - [공식 서비스](https://www.meshy.ai/)
- **Text2Mesh** (텍스트 설명 기반 3D 메쉬 스타일링)
  - [GitHub](https://github.com/threedle/text2mesh)
- **GET3D** (이미지/텍스트 → 3D 생성, NVIDIA)
  - [GitHub](https://github.com/NVlabs/GET3D)
- **ControlNet** (2D 이미지에서 3D 구조 추정, 3D 확장 포함)
  - [GitHub](https://github.com/lllyasviel/ControlNet)
- **Stable Video Diffusion** (2D 이미지 → 3D/동영상 변환, Stability AI)
  - [GitHub](https://github.com/Stability-AI/stable-video-diffusion)

### 3.2 3D 아바타/신체 모델링
- **SMPL** (3D 인체 파라메트릭 모델)
  - [GitHub](https://github.com/vchoutas/smpl)
- **SMPL-X** (3D 인체 파라메트릭 모델, 확장형)
  - [GitHub](https://github.com/vchoutas/smplx)
- **MakeHuman** (오픈소스 3D 아바타 생성)
  - [공식 사이트](http://www.makehumancommunity.org/)
- **ReadyPlayerMe** (웹 기반 3D 아바타 생성)
  - [공식 사이트](https://www.readyplayer.me/)

### 3.3 3D 의상/인체 시뮬레이션 소프트웨어
- **CLO3D** (상용)
  - [공식 사이트](https://www.clo3d.com/)
- **Marvelous Designer** (상용)
  - [공식 사이트](https://www.marvelousdesigner.com/)
- **Blender** (오픈소스 3D 모델링/시뮬레이션)
  - [공식 사이트](https://www.blender.org/)
- **Mixamo** (3D 캐릭터 리깅/애니메이션, Adobe)
  - [공식 사이트](https://www.mixamo.com/)

### 3.4 웹/모바일 3D 뷰어
- **Three.js** (웹 기반 3D 렌더링)
  - [공식 사이트](https://threejs.org/)
- **Babylon.js** (웹 기반 3D 엔진)
  - [공식 사이트](https://www.babylonjs.com/)
- **Unity WebGL** (Unity 엔진의 웹 3D 빌드)
  - [공식 사이트](https://unity.com/solutions/webgl)

## 4. LLaVA/ChatGarment와의 연계
- LLaVA/ChatGarment의 텍스트 설명 결과를 3D 생성 AI의 프롬프트로 활용 가능
- 예시 워크플로우:
  1. LLaVA로 이미지의 포즈/의상/외형을 텍스트로 추출
  2. 해당 텍스트를 3D 생성 AI(예: Meshy, PIFuHD 등)에 입력
  3. 3D 모델 생성 및 시뮬레이션

## 5. 향후 개발 목표
- LLaVA/ChatGarment의 텍스트 설명 결과를 자동으로 3D 생성 AI에 연동하는 파이프라인 개발
- 3D 의상/인체/포즈 시뮬레이션 자동화
- 사용자 맞춤형 3D 모델 생성 및 가상 피팅/시각화 지원
- 2D-3D 변환 AI와의 통합 및 워크플로우 자동화

## 6. 참고 키워드/논문/서비스
- 2D-to-3D Garment Reconstruction
- Virtual Try-On / Virtual Fitting
- 3D Garment Transfer
- AI-based 3D Human/Cloth Modeling
- Web-based 3D Viewer

## 7. ChatGarment 오픈소스 다운로드 및 설치 방법

### 7.1 ChatGarment 소개
- ChatGarment는 2D 의류 이미지를 3D 의상 모델로 변환하는 AI 모델입니다.
- [GitHub](https://github.com/chatgarment/chatgarment)에서 오픈소스로 제공됩니다.

### 7.2 다운로드 및 설치 방법
1. **GitHub 저장소 클론**
   ```bash
   git clone https://github.com/chatgarment/chatgarment.git
   cd chatgarment
   ```

2. **의존성 설치**
   - Python 3.8 이상이 필요합니다.
   - 필요한 패키지를 설치합니다.
     ```bash
     pip install -r requirements.txt
     ```

3. **모델 다운로드**
   - HuggingFace에서 모델 가중치를 다운로드합니다.
     ```bash
     python download_model.py
     ```

4. **실행 방법**
   - 기본 추론 스크립트를 실행합니다.
     ```bash
     python inference.py --input_image path/to/your/image.jpg --output_dir path/to/output
     ```

5. **추가 설정**
   - `config.yaml` 파일에서 모델 설정을 조정할 수 있습니다.
   - GPU 메모리 사용량, 배치 크기 등을 설정할 수 있습니다.

### 7.3 주의사항
- 모델 실행 시 GPU가 필요합니다 (NVIDIA GPU 권장).
- CUDA 및 cuDNN이 설치되어 있어야 합니다.
- 모델 가중치 파일은 약 4GB의 저장 공간이 필요합니다.

### 7.4 참고 자료
- [ChatGarment 공식 문서](https://chatgarment.github.io/)
- [논문](https://arxiv.org/abs/2404.01483)

## 8. ChatGarment 데이터셋 및 LLaVA-v1.5-7b 모델 다운로드 링크
- **ChatGarment 데이터셋**: [HuggingFace](https://huggingface.co/datasets/sy000/ChatGarmentDataset/tree/main)
- **LLaVA-v1.5-7b 모델**: [HuggingFace](https://huggingface.co/liuhaotian/llava-v1.5-7b/tree/main) 